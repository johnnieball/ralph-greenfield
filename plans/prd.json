{
  "project": "devpulse",
  "branchName": "ralph/devpulse-mvp",
  "description": "Web app that analyses merged GitHub PRs via LLM to produce gamified developer productivity scores. Engineers connect GitHub, the system scores each merged PR on complexity and impact using AI analysis of the code diff (never human metadata), and displays results on a competitive team leaderboard with a racing line chart. Built with Next.js (App Router), Tailwind CSS, Drizzle ORM with SQLite, and LLM providers via OpenRouter and Cerebras.",
  "userStories": [
    {
      "id": "US-001a",
      "title": "Project scaffold",
      "description": "Set up the foundational Next.js project with Tailwind CSS, environment configuration, and build tooling so all subsequent stories have a working development environment.",
      "acceptanceCriteria": [
        "bun run dev starts the Next.js development server without errors",
        "A smoke-test page at route / renders an HTML page containing the text 'DevPulse'",
        "Tailwind CSS is configured with darkMode: 'class'",
        "bun run build produces a production build without errors",
        "bun run typecheck passes with zero errors",
        "A .env.example file lists all required environment variables with placeholder values: GITHUB_CLIENT_ID, GITHUB_CLIENT_SECRET, NEXTAUTH_SECRET, NEXTAUTH_URL, OPENROUTER_API_KEY, CEREBRAS_API_KEY, LLM_PROVIDER (openrouter or cerebras), LLM_MODEL",
        "A .env file is created from .env.example with dummy values (e.g. NEXTAUTH_SECRET=dev-secret-change-me) so that bun run build and bun run dev succeed without real credentials"
      ],
      "priority": 1,
      "passes": true,
      "notes": "WORKSTREAM A (Infrastructure). Foundation story — everything depends on this. Use Next.js App Router (not Pages Router). Configure Tailwind in tailwind.config.ts. The data/ directory and .env should be gitignored but .env must exist with dummy values for builds to succeed — NextAuth reads env vars at module level. This is a non-TDD bootstrap story — verify each piece works but no red-green-refactor cycle. Design tokens are defined in US-013."
    },
    {
      "id": "US-001b",
      "title": "Drizzle ORM smoke test",
      "description": "Configure Drizzle ORM with better-sqlite3 and verify it can create and query a table, proving the ORM layer works end-to-end.",
      "acceptanceCriteria": [
        "Drizzle ORM is configured with better-sqlite3 and a database file at data/devpulse.db",
        "A Drizzle migration can create and query a test table (verified by a test)"
      ],
      "priority": 2,
      "passes": false,
      "notes": "WORKSTREAM A (Infrastructure). Depends on US-001a (project scaffold). First TDD-able story — write a failing test that expects a query result from a test table, then configure Drizzle and create a migration to make it pass."
    },
    {
      "id": "US-002",
      "title": "Core domain types and validation schemas",
      "description": "Define Zod schemas for the core domain model: users, organisations, PR metadata, analysis results, and Pulse Scores. These types are the contract between every module in the system.",
      "acceptanceCriteria": [
        "UserSchema validates an object with id (string), githubId (number), username (string), avatarUrl (string), and createdAt (Date)",
        "OrgSchema validates an object with id (string), githubId (number), name (string), avatarUrl (string)",
        "PRMetadataSchema validates: prGithubId (number), repoName (string), prNumber (number), authorUsername (string), filesChanged (number), additions (number), deletions (number), mergedAt (Date)",
        "PRAnalysisSchema validates: complexity (number 0-100), impact (number 0-100), category (Zod enum: 'feature' | 'bugfix' | 'refactor' | 'infrastructure' | 'chore'), reasoning (string), compositeScore (number)",
        "Each schema rejects invalid input with error messages that name the invalid field",
        "A parseX(input: unknown) function exists for each schema, returning typed data or throwing a ValidationError with structured error details"
      ],
      "priority": 3,
      "passes": false,
      "notes": "WORKSTREAM A (Schema). Foundation types referenced by every other workstream. The category field must be a Zod enum (not a union of string literals) so it can be reused in database column types and API responses. compositeScore is stored on PRAnalysis rather than computed on the fly — US-009 calculates it before persistence."
    },
    {
      "id": "US-003a",
      "title": "Database schema and UserRepository",
      "description": "Define the Drizzle database schema for all core tables and implement the UserRepository with a GitHub upsert method.",
      "acceptanceCriteria": [
        "Drizzle schema defines tables: users, organisations, userOrgs (join table linking users to their GitHub orgs), analyses (a batch analysis run with status), prScores (individual PR scores linked to an analysis)",
        "The prScores table stores scores and metadata only — no columns exist for diff content, patch text, or source code",
        "UserRepository provides upsertFromGitHub(db, githubUser): Promise<User> that creates or updates a user by githubId",
        "All repository methods accept a db parameter (Drizzle instance) as their first argument for testability — no module-level database singleton"
      ],
      "priority": 4,
      "passes": false,
      "notes": "WORKSTREAM A (Data). Depends on US-001b (Drizzle config), US-002 (domain types). The db parameter injection is essential — tests must use an in-memory SQLite database, not the file-based one. The analyses table tracks batch runs so the UI can show progress and historical results."
    },
    {
      "id": "US-003b",
      "title": "AnalysisRepository and OrgRepository",
      "description": "Implement the AnalysisRepository (create, addPRScore, complete, getLeaderboard) and OrgRepository (syncUserOrgs) on top of the established schema.",
      "acceptanceCriteria": [
        "AnalysisRepository provides create(db, orgId, weekStarting): Promise<Analysis> returning a record with generated id and status 'pending'",
        "AnalysisRepository provides addPRScore(db, analysisId, prScore): Promise<void> that inserts a scored PR linked to the analysis",
        "AnalysisRepository provides complete(db, analysisId, summary): Promise<void> that marks an analysis as 'complete' with aggregate stats",
        "OrgRepository provides syncUserOrgs(db, userId, orgs: GitHubOrg[]): Promise<void> that replaces the user's org memberships with the provided list",
        "AnalysisRepository provides getLeaderboard(db, analysisId): Promise<LeaderboardEntry[]> returning developers ranked by total composite score descending"
      ],
      "priority": 5,
      "passes": false,
      "notes": "WORKSTREAM A (Data). Depends on US-003a (schema and tables). Each repository method is independently testable against in-memory SQLite. US-010 (pipeline) and US-011/012 (API) depend on this interface."
    },
    {
      "id": "US-004",
      "title": "GitHub OAuth authentication",
      "description": "Implement GitHub OAuth sign-in using NextAuth.js. Users authenticate with GitHub, and their profile is stored in the database on first sign-in.",
      "acceptanceCriteria": [
        "NextAuth is configured with the GitHub provider requesting read:org and repo scopes",
        "On successful sign-in, the user's GitHub profile is upserted via UserRepository.upsertFromGitHub",
        "The NextAuth session includes the user's id, username, avatarUrl, and accessToken",
        "Unauthenticated requests to protected API routes return 401 with { error: 'Unauthorised' }",
        "GITHUB_CLIENT_ID and GITHUB_CLIENT_SECRET are read from environment variables; missing values throw a ConfigurationError at startup"
      ],
      "priority": 6,
      "passes": false,
      "notes": "WORKSTREAM B (Auth). Depends on US-001a (Next.js), US-003a (UserRepository). The access token stored in the session is used by US-005/006/007 to call the GitHub API on behalf of the user. NextAuth handles /api/auth/signin and /api/auth/callback/github routes by convention — these are framework-provided and not TDD-able, so they are not acceptance criteria. Focus tests on the upsert logic, session shape, and 401 guard. Use next-auth v5 (Auth.js)."
    },
    {
      "id": "US-005",
      "title": "GitHub API client — fetch user organisations",
      "description": "Create a GitHub API client module that fetches the authenticated user's organisations. The client is injected as a dependency for testability.",
      "acceptanceCriteria": [
        "GitHubClient is a class that accepts an accessToken in its constructor",
        "gitHubClient.listOrgs() returns Promise<GitHubOrg[]> with id, login, and avatarUrl for each org",
        "listOrgs throws a GitHubApiError if the API returns a non-200 status, including the status code and response body in the error",
        "listOrgs handles GitHub pagination (follows Link header rel=next) to return all orgs",
        "Rate limit headers (X-RateLimit-Remaining) are checked; if remaining is below 10, a warning is logged via an injected logger (optional, no-op if not provided)",
        "All HTTP calls go through an injected fetch function (defaults to global fetch) for testability"
      ],
      "priority": 7,
      "passes": false,
      "notes": "WORKSTREAM B (GitHub). Depends on US-004 (access token from session). The injected fetch is critical — tests must not hit the real GitHub API. US-006 and US-007 extend this same GitHubClient class with additional methods. The pagination handling matters — orgs with many repos will have paginated responses."
    },
    {
      "id": "US-006",
      "title": "GitHub API client — fetch merged PRs",
      "description": "Extend the GitHub API client to fetch all merged pull requests for an organisation's repositories within a date range.",
      "acceptanceCriteria": [
        "gitHubClient.listMergedPRs(org, since, until) returns Promise<PRMetadata[]> for all merged PRs across the org's repos in the date range",
        "The method first fetches the org's repositories, then fetches merged PRs for each repo",
        "Only PRs with merged_at within the since/until range are included",
        "PRs are returned as typed PRMetadata objects matching US-002's schema",
        "If a single repo's PR fetch fails, the error is captured and other repos continue — returns { prs: PRMetadata[], errors: GitHubApiError[] }",
        "Repositories with zero merged PRs in the range are silently skipped"
      ],
      "priority": 8,
      "passes": false,
      "notes": "WORKSTREAM B (GitHub). Depends on US-005 (GitHubClient class). This method makes many API calls (one per repo plus pagination) so rate limiting from US-005 applies. US-010 (analysis pipeline) consumes this. The partial-success pattern (valid PRs + errors) is important — the pipeline must not fail because one repo is inaccessible."
    },
    {
      "id": "US-007",
      "title": "GitHub API client — fetch PR diff",
      "description": "Extend the GitHub API client to fetch the diff content for a specific pull request. This content is ephemeral — used for scoring then discarded, never persisted.",
      "acceptanceCriteria": [
        "gitHubClient.getPRDiff(owner, repo, prNumber) returns Promise<PRDiff> containing the patch text and a structured summary of files changed with their paths, additions, and deletions",
        "The diff is fetched using GitHub's application/vnd.github.v3.diff media type",
        "If the diff exceeds 100KB, it is truncated to the first 100KB and PRDiff.truncated is set to true",
        "getPRDiff throws a GitHubApiError if the PR is not found or the API returns an error",
        "The returned PRDiff never contains full file contents — only diff hunks"
      ],
      "priority": 9,
      "passes": false,
      "notes": "WORKSTREAM B (GitHub). Depends on US-005 (GitHubClient class). The 100KB truncation is important — some PRs have enormous diffs (generated files, lock files) that would blow the LLM context window. US-009 (scoring engine) consumes this. The diff content must never be stored in the database — ephemeral code, persistent scores."
    },
    {
      "id": "US-008a",
      "title": "LLM provider interface and OpenRouterProvider",
      "description": "Create the LLM provider interface and the OpenRouter implementation. The scoring engine calls this interface without knowing which provider is active.",
      "acceptanceCriteria": [
        "LLMProvider interface defines complete(prompt: string, options?: { maxTokens?: number, temperature?: number }): Promise<LLMResponse> where LLMResponse has content (string) and usage ({ promptTokens, completionTokens })",
        "OpenRouterProvider implements LLMProvider, sending requests to the OpenRouter API with a configurable model name",
        "OpenRouterProvider throws an LLMProviderError on non-200 responses, including the status code and provider name in the error",
        "OpenRouterProvider accepts apiKey and model in its constructor; missing apiKey throws ConfigurationError",
        "All HTTP calls go through an injected fetch function for testability"
      ],
      "priority": 10,
      "passes": false,
      "notes": "WORKSTREAM C (Scoring). No dependencies on GitHub workstream — can be built independently after US-002 (domain types). The injected fetch is essential for testing. US-008b adds the second provider and factory. Both OpenRouter and Cerebras use OpenAI-compatible APIs so implementations will be similar, but do NOT prematurely abstract them into a single class — keep separate so they can diverge as provider APIs evolve."
    },
    {
      "id": "US-008b",
      "title": "CerebrasProvider and createProvider factory",
      "description": "Add the Cerebras LLM provider implementation and a factory function that returns the correct provider based on configuration.",
      "acceptanceCriteria": [
        "CerebrasProvider implements LLMProvider, sending requests to the Cerebras API with a configurable model name",
        "CerebrasProvider throws an LLMProviderError on non-200 responses, including the status code and provider name in the error",
        "CerebrasProvider accepts apiKey and model in its constructor; missing apiKey throws ConfigurationError",
        "createProvider(config: { provider: 'openrouter' | 'cerebras', apiKey: string, model: string }): LLMProvider factory function returns the correct implementation",
        "All HTTP calls go through an injected fetch function for testability"
      ],
      "priority": 11,
      "passes": false,
      "notes": "WORKSTREAM C (Scoring). Depends on US-008a (LLMProvider interface). Completes the provider abstraction. Testing: mock fetch and verify correct API URL, headers, and request body for Cerebras. Test factory returns correct implementation for each provider string."
    },
    {
      "id": "US-009",
      "title": "PR scoring engine",
      "description": "Build the scoring engine that takes a PR diff and metadata, constructs a prompt, sends it to the LLM, and parses the structured response into a typed PRAnalysis.",
      "acceptanceCriteria": [
        "scorePR(pr: PRMetadata, diff: PRDiff, provider: LLMProvider): Promise<PRAnalysis> returns a validated analysis result",
        "The prompt instructs the LLM to return JSON with fields: complexity (0-100), impact (0-100), category (one of the five enum values), and reasoning (1-3 sentences)",
        "The prompt includes only code-derived signals: the diff content, file paths, additions/deletions counts, and languages detected from file extensions — never commit messages, PR titles, or human-authored metadata",
        "The LLM response is parsed as JSON and validated against PRAnalysisSchema; if parsing fails, a ScoringError is thrown with the raw response attached for debugging",
        "compositeScore is calculated as Math.round((complexity * impact) / 100) and included in the returned analysis",
        "If diff.truncated is true, the prompt includes a note that the diff was truncated and the LLM should score based on available content",
        "The function is stateless — all dependencies (provider, PR data) are passed as arguments"
      ],
      "priority": 12,
      "passes": false,
      "notes": "WORKSTREAM C (Scoring). Depends on US-002 (PRAnalysisSchema), US-007 (PRDiff type), US-008a (LLMProvider). This is the heart of the product. Keep the prompt as a template string in a dedicated file (e.g. src/lib/scorer/prompt.ts) so it is easy to iterate on. The code-only constraint is non-negotiable per the spec. The multiplicative formula (complexity * impact / 100) is intentional — high complexity with low impact should score low. Include edge-case test values in the scoring tests: (100, 0) → 0, (0, 100) → 0, (50, 50) → 25, (90, 10) → 9, (100, 100) → 100. Testing hint: mock the LLMProvider to return known JSON responses; test prompt construction and response parsing as separate concerns."
    },
    {
      "id": "US-010",
      "title": "Analysis pipeline orchestration",
      "description": "Orchestrate the full analysis pipeline: fetch PRs for an org, fetch diffs, score each PR via LLM, and persist results. The pipeline reports progress and handles individual PR failures gracefully.",
      "acceptanceCriteria": [
        "runAnalysis(options: AnalysisOptions): Promise<AnalysisResult> orchestrates the full pipeline, where AnalysisOptions contains org, since, until, github (GitHubClient), provider (LLMProvider), db (DrizzleInstance), and optional onProgress callback",
        "The pipeline executes in discrete stages: fetchPRs, fetchDiffs, scorePRs, persistResults",
        "onProgress is called with { phase: string, completed: number, total: number } after each PR is scored",
        "If scoring fails for an individual PR, the error is captured in AnalysisResult.errors and other PRs continue",
        "If fetching a diff fails for a PR, that PR is skipped with an error and does not block others",
        "AnalysisResult contains analysisId, prsScored (number), prsFailed (number), errors (AnalysisError[]), and leaderboard (LeaderboardEntry[])",
        "All dependencies are injected via the options parameter — the pipeline creates no clients or connections internally"
      ],
      "priority": 13,
      "passes": false,
      "notes": "WORKSTREAM C+D (Pipeline). Depends on US-003b (AnalysisRepository), US-006 (listMergedPRs), US-007 (getPRDiff), US-009 (scorePR). Integration point tying workstreams B and C together. The discrete stages matter — US-011 exposes progress through the API. The onProgress callback drives the UI progress indicator. Testing: mock all three boundaries (GitHub, LLM, database) and verify orchestration logic, especially partial-failure scenarios."
    },
    {
      "id": "US-014a",
      "title": "User orgs API endpoint",
      "description": "Create an API endpoint that returns the authenticated user's GitHub organisations and syncs their org memberships to the database.",
      "acceptanceCriteria": [
        "GET /api/user/orgs returns the authenticated user's GitHub organisations",
        "The endpoint calls gitHubClient.listOrgs with the session's access token",
        "The endpoint persists org memberships via OrgRepository.syncUserOrgs before returning",
        "Each org in the response includes id, name, and avatarUrl",
        "The endpoint returns 401 if no session"
      ],
      "priority": 14,
      "passes": false,
      "notes": "WORKSTREAM D (API). Depends on US-004 (auth session + access token), US-005 (GitHubClient.listOrgs), US-003b (OrgRepository.syncUserOrgs). Extracted from the original US-014 to resolve a circular dependency with US-011 — the analysis endpoint needs the userOrgs table populated, which this endpoint handles. Must be built before US-011."
    },
    {
      "id": "US-011",
      "title": "Analysis API endpoints",
      "description": "Create API endpoints to trigger an analysis and check its status. These connect the UI to the analysis pipeline.",
      "acceptanceCriteria": [
        "POST /api/analyse accepts { orgId: string }, creates a new analysis, starts the pipeline, and returns { analysisId: string }",
        "GET /api/analyse/[id] returns the analysis status: { status: 'pending' | 'running' | 'complete' | 'failed', progress?: AnalysisProgress, result?: AnalysisResult }",
        "The POST endpoint requires authentication and returns 401 if no session",
        "The POST endpoint returns 400 if orgId is missing, and 403 if the user does not belong to the org (checked against the userOrgs join table)",
        "The analysis runs asynchronously — POST starts the pipeline via a fire-and-forget Promise and returns immediately with the analysisId; the client polls GET for progress",
        "If an analysis is already running for the same org, POST returns 409 with { error: 'Analysis already in progress', analysisId: string }"
      ],
      "priority": 15,
      "passes": false,
      "notes": "WORKSTREAM D (API). Depends on US-004 (auth session), US-010 (runAnalysis), US-014a (userOrgs populated by the orgs endpoint). The async pattern uses a fire-and-forget Promise — acceptable for MVP since SQLite is local and there is no need for a job queue. The POST handler calls runAnalysis() without await, catching errors via .catch() to update analysis status to 'failed'. Testing hint: mock the analysis pipeline and test the HTTP layer — request validation, auth checks, status transitions."
    },
    {
      "id": "US-012",
      "title": "Leaderboard API endpoint",
      "description": "Create an API endpoint that returns the team leaderboard for a completed analysis, with developers ranked by their total weekly Pulse Score (sum of composite PR scores).",
      "acceptanceCriteria": [
        "GET /api/leaderboard/[analysisId] returns { entries: LeaderboardEntry[], weekStarting: string, orgName: string }",
        "LeaderboardEntry contains: rank (number), username (string), avatarUrl (string), totalScore (number), prCount (number), categoryBreakdown (record of category to count), prs (array of { repoName, prNumber, compositeScore, complexity, impact, category, reasoning, mergedAt })",
        "Entries are sorted by totalScore descending with rank assigned sequentially starting at 1",
        "The endpoint returns 404 if the analysis does not exist",
        "The endpoint returns 400 with { error: 'Analysis not complete' } if the analysis status is not 'complete'",
        "The endpoint requires authentication and returns 401 if no session"
      ],
      "priority": 16,
      "passes": false,
      "notes": "WORKSTREAM D (API). Depends on US-003b (getLeaderboard), US-011 (analysis completion). The prs array nested in each entry gives the UI everything it needs for the PR detail expansion (US-017) without a second API call. Including reasoning in the response is deliberate — it avoids per-PR API calls when users expand a row."
    },
    {
      "id": "US-013",
      "title": "App shell — dark mode layout and design tokens",
      "description": "Create the application shell with dark mode styling, design tokens, responsive layout, navigation header, and root page routing. This is the visual foundation for all UI components.",
      "acceptanceCriteria": [
        "The root layout applies the dark class to <html> and sets the background to --color-bg (#09090b)",
        "Tailwind config extends the theme with DevPulse design tokens: pulse (#39FF14), bg-base (#09090b), text-primary (#fafafa), and accent colours blue (#3B82F6), pink (#EC4899), amber (#F59E0B), purple (#8B5CF6)",
        "Design tokens are defined as CSS custom properties: --color-pulse (#39FF14), --color-bg (#09090b), --color-text (#fafafa)",
        "A Header component renders the DevPulse name and a sign-in/sign-out button based on session state",
        "The layout is responsive: single-column on mobile (< 768px), max-width container centred on desktop",
        "Typography uses a clean sans-serif font stack (Inter or system fonts)",
        "A DEVELOPER_COLOURS constant exports an array of the accent colours for assigning to chart lines and developer avatars",
        "The root page / redirects to /dashboard if authenticated, or shows a landing page with a 'Sign in with GitHub' button if not"
      ],
      "priority": 17,
      "passes": false,
      "notes": "WORKSTREAM E (UI). Depends on US-001a (Tailwind), US-004 (auth session for header). Establishes the visual foundation — all subsequent UI stories build inside this shell. The DEVELOPER_COLOURS array is used by US-016b (racing line chart) and US-015 (leaderboard) to assign consistent colours to developers. The root page redirect/landing was moved here from US-014 to keep the dashboard stories focused."
    },
    {
      "id": "US-014b",
      "title": "Dashboard — org selector and analysis trigger",
      "description": "Build the dashboard page where users select an organisation and trigger an analysis run.",
      "acceptanceCriteria": [
        "The dashboard page at /dashboard is protected — unauthenticated users redirect to sign-in",
        "A dropdown shows the user's GitHub orgs with avatars and names, populated from GET /api/user/orgs",
        "An 'Analyse Last 7 Days' button triggers POST /api/analyse with the selected org"
      ],
      "priority": 18,
      "passes": false,
      "notes": "WORKSTREAM E (UI). Depends on US-013 (app shell), US-014a (user orgs API), US-011 (analysis API). This is the first half of the dashboard — the user selects an org and triggers analysis. US-014c handles showing progress and results."
    },
    {
      "id": "US-014c",
      "title": "Dashboard — progress and results",
      "description": "Add progress tracking, result rendering, and error handling to the dashboard page during and after analysis.",
      "acceptanceCriteria": [
        "While analysis is running, a progress bar shows completed/total PRs scored, updated by polling GET /api/analyse/[id] every 2 seconds; polling stops on status 'complete' or 'failed', or after 5 minutes, whichever comes first",
        "When analysis completes, the page renders the Leaderboard and RacingLineChart components with the results",
        "If analysis completed with partial failures (prsFailed > 0), a warning banner displays 'N PRs could not be scored' above the results",
        "If analysis fails entirely, an error message displays the failure reason"
      ],
      "priority": 19,
      "passes": false,
      "notes": "WORKSTREAM E (UI). Depends on US-014b (dashboard page and trigger), US-011 (analysis status polling), US-012 (leaderboard data). US-015 (leaderboard) and US-016b (chart) are rendered as child components here."
    },
    {
      "id": "US-015",
      "title": "Team leaderboard component",
      "description": "Build the team leaderboard displaying developers ranked by weekly Pulse Score with category breakdowns.",
      "acceptanceCriteria": [
        "Leaderboard component accepts entries (LeaderboardEntry[]) and renders developer cards in rank order",
        "Each card displays: rank number, GitHub avatar, username, total Pulse Score (large, in pulse green), PR count, and category tags coloured by category type",
        "The top-ranked developer's card has a distinct highlight treatment (border glow or background accent)",
        "Each card displays the developer's total Pulse Score as a numeric value",
        "Cards are clickable — clicking calls onSelect(entry) to trigger the PR detail view (US-017)",
        "The component renders a 'No data yet' message when entries is an empty array"
      ],
      "priority": 20,
      "passes": false,
      "notes": "WORKSTREAM E (UI). Depends on US-012 (LeaderboardEntry type and data shape), US-013 (design tokens). Category tag colours: feature = blue, bugfix = pink, refactor = purple, infrastructure = amber, chore = gray. The onSelect callback decouples this component from navigation — US-014c handles what happens on click. Nice-to-have: count-up animation from 0 to final score using requestAnimationFrame (implementation note, not a pass/fail criterion)."
    },
    {
      "id": "US-016a",
      "title": "Chart data transform",
      "description": "Create the pure data transform function that converts leaderboard entries into chart-ready cumulative score data.",
      "acceptanceCriteria": [
        "A toChartData(entries: LeaderboardEntry[], colours: string[]): ChartData[] function transforms leaderboard entries into chart-ready data",
        "Each ChartData entry has username (string), colour (string), and points (array of { date: Date, cumulativeScore: number })",
        "Points are computed by grouping each developer's PRs by mergedAt date and calculating running cumulative scores",
        "The function is pure — no side effects, no API calls"
      ],
      "priority": 21,
      "passes": false,
      "notes": "WORKSTREAM E (UI). Depends on US-012 (LeaderboardEntry with prs containing mergedAt and compositeScore). This is the bridge between the leaderboard API response and the chart component's input. Highly TDD-able — pure function with deterministic inputs and outputs."
    },
    {
      "id": "US-016b",
      "title": "Racing line chart component",
      "description": "Build the racing line chart showing cumulative Pulse Scores across the week for each team member using Recharts.",
      "acceptanceCriteria": [
        "RacingLineChart component accepts an array of ChartData and renders a line chart",
        "Each developer renders as a coloured line showing their cumulative score over the week",
        "The X axis spans Monday to the current day; the Y axis auto-scales to the highest cumulative score",
        "The chart is responsive — fills its container width with a minimum height of 300px",
        "Developer colours are assigned from the DEVELOPER_COLOURS array defined in US-013",
        "The chart renders one SVG path element per developer"
      ],
      "priority": 22,
      "passes": false,
      "notes": "WORKSTREAM E (UI). Depends on US-016a (toChartData), US-013 (DEVELOPER_COLOURS). Use Recharts for MVP simplicity. Nice-to-have visual effects (not pass/fail criteria): gradient fill beneath lines at 20% opacity, glow effect on the leading developer's line via CSS drop-shadow, progressive draw animation on first render. These can be added as polish after core functionality works."
    },
    {
      "id": "US-017",
      "title": "PR detail expansion view",
      "description": "When a user clicks a developer card on the leaderboard, expand inline to show their individual PRs with scores and the LLM's reasoning.",
      "acceptanceCriteria": [
        "Clicking a leaderboard card expands an inline detail panel below the card showing the developer's PRs",
        "Each PR row displays: repository name, PR number as a link to GitHub (https://github/{org}/{repo}/pull/{number}), files changed count, complexity score, impact score, composite score, and category tag",
        "Clicking a PR row toggles the LLM reasoning text for that score",
        "PR rows are sorted by composite score descending",
        "The detail panel container has aria-expanded matching its visibility state",
        "Clicking the same developer card again collapses the detail panel",
        "Only one developer's detail panel is open at a time — expanding one collapses the previous"
      ],
      "priority": 23,
      "passes": false,
      "notes": "WORKSTREAM E (UI). Depends on US-012 (PR data nested in leaderboard response), US-015 (leaderboard card's onSelect). The reasoning text is the key trust-building feature — it shows users why a PR scored what it scored. Keep the expansion state as local React state, no state management library needed. The GitHub link uses the org name from the analysis context. Nice-to-have: slide transition animation on expand/collapse (implementation note, not a pass/fail criterion)."
    }
  ]
}
